<?xml version="1.0" encoding="utf-8"?>
<Technique>

	<Include System="Transformation"/>
	<Include System="Camera"/>

	<FrameBuffer System="Default"/>

	<Sampler Name="ConeTracingSampler">
		<State BorderColor="0.00, 0.00, 0.00, 0.00"/>
		<State AddressingModeR="ClampToBorder"/>
		<State AddressingModeS="ClampToBorder"/>
		<State AddressingModeT="ClampToBorder"/>
		<State MagFilterMode="Linear"/>
		<State MinFilterMode="LinearMipmapLinear"/>
	</Sampler>

	<Texture Name="voxels" TextureType="Texture3D" TexelType="FloatV4" Sampler="ConeTracingSampler"/>

	<UniformBuffer Name="NeverChanged">
		<Variable Name="voxelVolumeCenter" Type="FloatV3"/>
		<Variable Name="voxelVolumeHalfSize" Type="Float"/>
	</UniformBuffer>

	<UniformBuffer Name="TracingParameter">
		<Variable Name="aperture" Type="Float"/>
	</UniformBuffer>
	
	<AttributeInput Name="position" Type="FloatV3"/>

	<RasterizerState>
		<State CullMode="None"/>
	</RasterizerState>

	<DepthStencilState>
	</DepthStencilState>

	<BlendState>
		<State BlendEnable="true"/>
		<State BlendOperation="Add"/>
		<State BlendOperationAlpha="Add"/>
		<State SourceBlend="One"/>
		<State SourceBlendAlpha="SourceAlpha"/>
		<State DestinationBlend="OneMinusSourceAlpha"/>
		<State DestinationBlendAlpha="OneMinusSourceAlpha"/>
	</BlendState>
	
	<Code>
		<![CDATA[
uniform sampler3D voxels;

uniform NeverChanged
{
	vec3 voxelVolumeCenter;
	float voxelVolumeHalfSize;
};

uniform TracingParameter
{
	float aperture;
};
		]]>
	</Code>

	<VertexShader>
		<Code>
			<![CDATA[
in vec3 position; // [-1, 1], should be the back face of the bounding box.
out vec3 wPosition;

void main()
{
	wPosition = XREX_Transform(XREX_ModelTransformation.WorldFromModel, position);
	gl_Position = XREX_TransformToClip(XREX_ModelTransformation.ClipFromModel, position);
}
			]]>
		</Code>
	</VertexShader>

	<FragmentShader>
		<Code>
			<![CDATA[
/*
 *	@r: sample size over voxel size.
 */
vec4 AdjustResult(vec4 value, float r)
{
	if (value.a < 0.0001)
	{
		return value;
	}
 	float adjustedAlpha = 1 - pow(1 - value.a, r);
 	return value * adjustedAlpha / value.a;
}


//#define STORE_OPTICAL_DEPTH // define this to store optical depth instead of alpha

const float OpticalDepthMax = 5; // alpha = 1 - e^(-optical depth)

/*
 *	Alpha to optical depth, mapped from [0, OpticalDepthMax] to [0, 1]
 */
float AlphaToPackedOpticalDepthF(float alpha) // used in voxel generation step, listed here as a reference
{
	return -log(1 - alpha) / OpticalDepthMax;
}

/*
 *	mapped optical depth to alpha, optical depth mapped from [0, OpticalDepthMax] to [0, 1]
 */
float PackedOpticalDepthToAlphaF(float packedOpticalDepth)
{
	return 1 - exp(-packedOpticalDepth * OpticalDepthMax);
}

/*
 *	Alpha to optical depth, mapped from [0, OpticalDepthMax] to [0, 1]
 */
vec4 AlphaToPackedOpticalDepth(vec4 alpha) // used in voxel generation step, listed here as a reference
{
	return -log(vec4(1) - alpha) / OpticalDepthMax;
}

/*
 *	mapped optical depth to alpha, optical depth mapped from [0, OpticalDepthMax] to [0, 1]
 */
vec4 PackedOpticalDepthToAlpha(vec4 packedOpticalDepth)
{
	return vec4(1) - exp(-packedOpticalDepth * OpticalDepthMax);
}

/*
 *	@vexelVolume: voxels range from [0, 1].
 */
vec4 Sample(sampler3D vexelVolume, float normalizedVoxelSize, vec3 normalizedSamplePoint, float normalizedSampleRadius)
{
	float normalizedSampleSize = normalizedSampleRadius * 2; // normalizedSampleSize is diameter
	float sampleLevel = log(normalizedSampleSize / normalizedVoxelSize) / log(2);
	vec4 result = textureLod(vexelVolume, normalizedSamplePoint, max(0, sampleLevel));
#ifdef STORE_OPTICAL_DEPTH
	result = PackedOpticalDepthToAlpha(result);
	//result.a = PackedOpticalDepthToAlphaF(result.a);
#else
	result = result;
#endif
	
	
	//result = AdjustResult(result, normalizedSampleSize / normalizedVoxelSize); // adjust result based on size difference
	return result;
}

/*
 *	Front to back accumulation.
 */
vec4 AccumulateColor(vec4 currentColor, vec4 newColor)
{
	return currentColor + (1 - currentColor.a) * newColor;
}


/*
 *	@vexelVolume: color should alpha pre-multiplied.
 *	@normalizedStartPoint: [0, 1], value outside this range is outside the volume.
 *	@return: alpha pre-multiplied color.
 */
vec4 ConeTrace(sampler3D vexelVolume, vec3 normalizedStartPoint, vec3 viewDirection, float coneAperture, float alphaThreshold)
{ // every values in this function are in texture coordinate, [0, 1]
	const ivec3 gridCounts = textureSize(vexelVolume, 0); // x,y,z should be same.
	const int gridCount = gridCounts.x;
	const float maxTracingDistance = 2; // TODO change to proper value
	const float voxelSize = float(1) / gridCount;
	const float sinHalfAperture = sin(coneAperture / 2);

	vec4 finalColor = vec4(0, 0, 0, 0); // alpha pre-multiplied color

	// the volume of first sample point should include the startPoint
	float currentSampleDistance = voxelSize / 2;
	float currentSampleRadius = voxelSize / 2;
	while (currentSampleDistance + currentSampleRadius < maxTracingDistance)
	{
		vec3 currentSamplePoint = normalizedStartPoint + viewDirection * currentSampleDistance;
		vec4 color = Sample(vexelVolume, voxelSize, currentSamplePoint, currentSampleRadius);
		finalColor = AccumulateColor(finalColor, color);
		if (finalColor.a > alphaThreshold)
		{
			break;
		}
		// next sphere inside the cone next to the current sample sphere.
		// (currentSampleDistance + currentSampleRadius + nextSampleRadius) * sin(sinHalfAperture) = nextSampleRadius
		float nextSampleRadius = (currentSampleDistance + currentSampleRadius) * sinHalfAperture / (1 - sinHalfAperture);
		if (nextSampleRadius < voxelSize / 2)
		{
			nextSampleRadius = voxelSize / 2;
		}
		currentSampleDistance += (currentSampleRadius + nextSampleRadius);
		currentSampleRadius = nextSampleRadius;
	}
	return finalColor;
}


			]]>
		</Code>
		<Code>
			<![CDATA[
const float AlphaThreshold = 0.99;

in vec3 wPosition;

out vec4 XREX_DefaultFrameBufferOutput;

void main()
{
	vec3 direction = normalize(wPosition - XREX_CameraTransformation.CameraPositionInWorld);
	// TODO why voxelVolumeHalfSize * 2, not voxelVolumeHalfSize works as what I supposed?
	vec3 normalizedStartPosition = ((XREX_CameraTransformation.CameraPositionInWorld - voxelVolumeCenter) / voxelVolumeHalfSize + vec3(1, 1, 1)) / 2;
	vec4 color = ConeTrace(voxels, normalizedStartPosition, direction, aperture, AlphaThreshold);
	XREX_DefaultFrameBufferOutput = color;
} // TODO ConeTrace start from near plane when used as direct rendering, not the viewing original.
			]]>
		</Code>
	</FragmentShader>



</Technique>
